{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vytvorenie slovníka dvojíc pre účely Named Entity Recognizing\n",
    "#### Creating a dictionary of pairs for the purposes of Named Entity Recognizing: Wiki page - type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projekt je momentalne rozdeleny do 2 časti.\n",
    "\n",
    "1. časť tvorí stahovanie potrebných súborov(wikipedia dump) na účely spracovania v projekte.\n",
    "2. časť tvorí parsovanie súborov spolu s priradením kategorie jednotlivym clankom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Part : Downloading Wikipedia articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stiahnutie dát zo stránky wikipédie. Vyfiltrovanie všetkých súborov, ktoré obsahujú v názve \"pages-articles\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://dumps.wikimedia.org/enwiki/20201001/'\n",
    "base_html = requests.get(base_url).text\n",
    "base_html[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li class=\"file\"><a href=\"/enwiki/20201001/enwiki-20201001-pages-articles-multistream.xml.bz2\">enwiki-20201001-pages-articles-multistream.xml.bz2</a> 17.5 GB</li>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_dump = BeautifulSoup(base_html, 'html.parser')\n",
    "soup_dump.find_all('li', {'class': 'file'}, limit = 10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enwiki-20201001-pages-articles-multistream.xml.bz2', ['17.5', 'GB']),\n",
       " ('enwiki-20201001-pages-articles-multistream-index.txt.bz2', ['215.8', 'MB']),\n",
       " ('enwiki-20201001-pages-articles-multistream1.xml-p1p41242.bz2',\n",
       "  ['231.7', 'MB']),\n",
       " ('enwiki-20201001-pages-articles-multistream-index1.txt-p1p41242.bz2',\n",
       "  ['222', 'KB']),\n",
       " ('enwiki-20201001-pages-articles-multistream2.xml-p41243p151573.bz2',\n",
       "  ['313.2', 'MB'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "for file in soup_dump.find_all('li', {'class': 'file'}):\n",
    "    text = file.text\n",
    "    if 'pages-articles' in text:\n",
    "        files.append((text.split()[0], text.split()[1:]))\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enwiki-20201001-pages-articles1.xml-p1p41242.bz2',\n",
       " 'enwiki-20201001-pages-articles2.xml-p41243p151573.bz2',\n",
       " 'enwiki-20201001-pages-articles3.xml-p151574p311329.bz2',\n",
       " 'enwiki-20201001-pages-articles4.xml-p311330p558391.bz2',\n",
       " 'enwiki-20201001-pages-articles5.xml-p558392p958045.bz2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_download = [file[0] for file in files if re.search('pages-articles\\d{1,2}.xml-p',file[0])]\n",
    "files_to_download[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Použitie knižnice keras na stiahnutie týchto súborov/datasetu. Stiahnú sa len tie súbory, ktoré ešte nie sú stahnuté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from keras.utils import get_file\n",
    "directory = '/home/xminarikd/.keras/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles1.xml-p1p41242.bz2\n",
      "242098176/242093817 [==============================] - 330s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles2.xml-p41243p151573.bz2\n",
      "324780032/324777650 [==============================] - 445s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles3.xml-p151574p311329.bz2\n",
      "352124928/352119906 [==============================] - 313s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles4.xml-p311330p558391.bz2\n",
      "389988352/389987127 [==============================] - 372s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles5.xml-p558392p958045.bz2\n",
      "420814848/420806959 [==============================] - 471s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles6.xml-p958046p1483661.bz2\n",
      "450748416/450745879 [==============================] - 553s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles7.xml-p1483662p2134111.bz2\n",
      "462512128/462504094 [==============================] - 385s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles8.xml-p2134112p2936260.bz2\n",
      "471654400/471652241 [==============================] - 344s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles9.xml-p2936261p4045402.bz2\n",
      "512147456/512145263 [==============================] - 485s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles10.xml-p4045403p5399366.bz2\n",
      "502456320/502449820 [==============================] - 357s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles11.xml-p5399367p6899366.bz2\n",
      "486776832/486770345 [==============================] - 393s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles11.xml-p6899367p7054859.bz2\n",
      "46866432/46859027 [==============================] - 69s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles12.xml-p7054860p8554859.bz2\n",
      "404406272/404401272 [==============================] - 624s 2us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles12.xml-p8554860p9172788.bz2\n",
      "164061184/164054426 [==============================] - 131s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles13.xml-p9172789p10672788.bz2\n",
      "330563584/330555755 [==============================] - 278s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles13.xml-p10672789p11659682.bz2\n",
      "229384192/229381099 [==============================] - 205s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles14.xml-p11659683p13159682.bz2\n",
      "393928704/393922075 [==============================] - 348s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles14.xml-p13159683p14324602.bz2\n",
      "273661952/273655291 [==============================] - 271s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles15.xml-p14324603p15824602.bz2\n",
      "355713024/355706040 [==============================] - 263s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles15.xml-p15824603p17324602.bz2\n",
      "307257344/307257124 [==============================] - 317s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles15.xml-p17324603p17460152.bz2\n",
      "28254208/28249729 [==============================] - 111s 4us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles16.xml-p17460153p18960152.bz2\n",
      "336871424/336865577 [==============================] - 308s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles16.xml-p18960153p20460152.bz2\n",
      "314253312/314246115 [==============================] - 205s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles16.xml-p20460153p20570392.bz2\n",
      "22953984/22949874 [==============================] - 35s 2us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles17.xml-p20570393p22070392.bz2\n",
      "351920128/351918604 [==============================] - 228s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles17.xml-p22070393p23570392.bz2\n",
      "362340352/362336803 [==============================] - 221s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles17.xml-p23570393p23716197.bz2\n",
      "40402944/40402767 [==============================] - 27s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles18.xml-p23716198p25216197.bz2\n",
      "375750656/375742870 [==============================] - 295s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles18.xml-p25216198p26716197.bz2\n",
      "347947008/347946542 [==============================] - 251s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles18.xml-p26716198p27121850.bz2\n",
      "87384064/87377512 [==============================] - 119s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles19.xml-p27121851p28621850.bz2\n",
      "337952768/337946504 [==============================] - 229s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles19.xml-p28621851p30121850.bz2\n",
      "297205760/297201089 [==============================] - 213s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles19.xml-p30121851p31308442.bz2\n",
      "281026560/281023102 [==============================] - 159s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles20.xml-p31308443p32808442.bz2\n",
      "383336448/383334873 [==============================] - 241s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles20.xml-p32808443p34308442.bz2\n",
      "349700096/349699080 [==============================] - 394s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles20.xml-p34308443p35522432.bz2\n",
      "259284992/259278058 [==============================] - 153s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles21.xml-p35522433p37022432.bz2\n",
      "351600640/351597304 [==============================] - 515s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles21.xml-p37022433p38522432.bz2\n",
      "340942848/340936052 [==============================] - 502s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles21.xml-p38522433p39996245.bz2\n",
      "345997312/345996096 [==============================] - 232s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles22.xml-p39996246p41496245.bz2\n",
      "340557824/340555294 [==============================] - 231s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles22.xml-p41496246p42996245.bz2\n",
      "351027200/351022715 [==============================] - 304s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles22.xml-p42996246p44496245.bz2\n",
      "354238464/354232150 [==============================] - 347s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles22.xml-p44496246p44788941.bz2\n",
      "55885824/55884326 [==============================] - 60s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles23.xml-p44788942p46288941.bz2\n",
      "228384768/228383839 [==============================] - 217s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles23.xml-p46288942p47788941.bz2\n",
      "362102784/362097862 [==============================] - 626s 2us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles23.xml-p47788942p49288941.bz2\n",
      "304455680/304454625 [==============================] - 328s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles23.xml-p49288942p50564553.bz2\n",
      "235069440/235065016 [==============================] - 175s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles24.xml-p50564554p52064553.bz2\n",
      "322166784/322159926 [==============================] - 269s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles24.xml-p52064554p53564553.bz2\n",
      "322420736/322418062 [==============================] - 255s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles24.xml-p53564554p55064553.bz2\n",
      "306626560/306624664 [==============================] - 192s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles24.xml-p55064554p56564553.bz2\n",
      "321986560/321985394 [==============================] - 189s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles24.xml-p56564554p57025655.bz2\n",
      "101703680/101699893 [==============================] - 63s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles25.xml-p57025656p58525655.bz2\n",
      "335503360/335498693 [==============================] - 193s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles25.xml-p58525656p60025655.bz2\n",
      "296157184/296156960 [==============================] - 233s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles25.xml-p60025656p61525655.bz2\n",
      "329154560/329146942 [==============================] - 217s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles25.xml-p61525656p62585850.bz2\n",
      "231440384/231434326 [==============================] - 145s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles26.xml-p62585851p63975909.bz2\n",
      "344973312/344965297 [==============================] - 321s 1us/step\n",
      "Downloading\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20201001/enwiki-20201001-pages-articles27.xml-p63975910p65475424.bz2\n",
      "310239232/310232346 [==============================] - 275s 1us/step\n"
     ]
    }
   ],
   "source": [
    "data_paths = []\n",
    "file_info = []\n",
    "\n",
    "for file in files_to_download:\n",
    "    path = directory + file\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        print('neexistuje')\n",
    "    # downaload only when file dont exist\n",
    "    if not os.path.exists(directory + file):\n",
    "        print('Downloading')\n",
    "        data_paths.append(get_file(file, base_url + file))\n",
    "        file_size = os.stat(path).st_size / 1e6\n",
    "        \n",
    "        # Find the number of articles\n",
    "        file_articles = int(file.split('p')[-1].split('.')[-2]) - int(file.split('p')[-2])\n",
    "        file_info.append((file, file_size, file_articles))\n",
    "        \n",
    "    # when file already exist\n",
    "    else:\n",
    "        data_paths.append(path)\n",
    "        file_size = os.stat(path).st_size / 1e6\n",
    "        \n",
    "        file_number = int(file.split('p')[-1].split('.')[-2]) - int(file.split('p')[-2])\n",
    "        file_info.append((file.split('-')[-1], file_size, file_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enwiki-20201001-pages-articles9.xml-p2936261p4045402.bz2',\n",
       "  512.145263,\n",
       "  1109141),\n",
       " ('enwiki-20201001-pages-articles10.xml-p4045403p5399366.bz2',\n",
       "  502.44982,\n",
       "  1353963),\n",
       " ('enwiki-20201001-pages-articles11.xml-p5399367p6899366.bz2',\n",
       "  486.770345,\n",
       "  1499999),\n",
       " ('enwiki-20201001-pages-articles8.xml-p2134112p2936260.bz2',\n",
       "  471.652241,\n",
       "  802148),\n",
       " ('enwiki-20201001-pages-articles7.xml-p1483662p2134111.bz2',\n",
       "  462.504094,\n",
       "  650449)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(file_info, key = lambda x: x[1], reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Part Parsing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsovanie prebieha postupne na všetkých súboroch v kompresovanom tvare. Na tento účel je použitý podproces \"bzcat\", ktorý číta a dodáva súbor po jednotlivých riadkoch. Na spracovanie týchto dát je použitý XML SAX parser. Tento parser obsahuje metódu ContentHandler, ktorá zabezpečuje uchovanie riadkov v buffery, pričom sa hľadajú tagy (page, title, text). Po nájdeni ukončovacieho znaku tagu page prebieha spracovanie celého článku.\n",
    "\n",
    "Z článku sú pomocou regulárnych výrazov extrahované informácie:\n",
    "* **infobox**\n",
    "    * atribúty infoboxu\n",
    "    * typ infoboxu\n",
    "* **kategórie čklánku**\n",
    "\n",
    "Následne na základe týchto informácií je určená kategória článku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import xml.sax\n",
    "import regex\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentálne sú priradzované kategórie: Person, Company, Organisation, Place.\n",
    "Priradzovanie prebieha podľa vyššieho poradia na základe parametrov v poradí:\n",
    "* **typ infoboxu** - či sa v zozname danej kategorie nachádza infobox daného článku\n",
    "* **atribúty infoboxu:**\n",
    "    * **person** - birth_date\n",
    "    * **company** - industry, trade_name, products, brands\n",
    "    * **organisation** - zatiaľ žiadne\n",
    "    * **place** - coordinates, locations _|neobsahuje|_ date, founded, founder, founders\n",
    "* **kategorie článku:**\n",
    "    * **organisation** - obsahuje v kategóriach slovo organisaion/s\n",
    "* **text článku** - zatiaľ nepoužité, ale plánované pre prípady, kedy článok neobsahuje infobox a kategórie neposkytnú žiadnu informáciu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Infobox and Infobox type from article text\n",
    "def ArticleHandler():\n",
    "    infobox_regex = '(?=\\{Infobox )(\\{([^{}]|(?1))*\\})'\n",
    "    inf_type_regex = '(?<=Infobox)(.*?)(?=(\\||\\n|<!-|<--))'\n",
    "    #https://regex101.com/r/1vJlms/1\n",
    "    inf_parameters = '(?(?<=\\|)|(?<=\\|\\s))(\\w*)\\s*=\\s*[\\w{\\[]'\n",
    "    #https://regex101.com/r/fl5hAw/1 https://regex101.com/r/Xj0fM3/1\n",
    "    redirect_title = '(?<=\\[\\[)(.*)(?=\\]\\])'\n",
    "    categories = '(?<=\\[\\[Category:)([^\\]]*)(?=\\]\\])'\n",
    "    \n",
    "    \n",
    "    def getCategories(text):\n",
    "        return regex.findall(categories, text)\n",
    "    \n",
    "    \n",
    "    def getArticleAtributes(infobox,text):\n",
    "        i_par = regex.findall(inf_parameters, infobox)\n",
    "        i_type = regex.search(inf_type_regex, infobox)\n",
    "        i_type = i_type.group(0).strip() if i_type is not None else \"none\"\n",
    "        return {'type': i_type.lower(), 'parameters': i_par, 'categories': list(getCategories(text))}\n",
    "        \n",
    "        \n",
    "    def isRedirect(text):\n",
    "        return regex.search(\"^#redirect\\s*\\[\\[(?i)\", text)\n",
    "        \n",
    "        \n",
    "    def getInfobox(text):\n",
    "        infobox = regex.search(infobox_regex, text)\n",
    "        return infobox.group() if infobox is not None else \"redirect\" if isRedirect(text) is not None else \"no infobox/redirect\"\n",
    "    \n",
    "    \n",
    "    def predictCategory(infobox, info, text):\n",
    "        if infobox not in ['redirect', 'no infobox/redirect']:\n",
    "            if info['type'] in persons or 'birth_date' in info['parameters']:\n",
    "                return \"Person\"\n",
    "            elif info['type'] in companies:\n",
    "                return 'Company'\n",
    "            elif any(i in info['parameters'] for i in ['industry', 'trade_name', 'products', 'brands']):\n",
    "                return 'W_Company'\n",
    "            elif list(filter(lambda x: regex.search('\\b(compan(y|ies))\\b(?i)', x), info['categories'])):\n",
    "                return 'Q_Company'\n",
    "            \n",
    "            elif info['type'] in organizations:\n",
    "                return \"Organization\"\n",
    "            elif list(filter(lambda x: regex.search('(organisations*)(?i)', x), info['categories'])):\n",
    "                return 'W_Organization'\n",
    "            \n",
    "            elif info['type'] in locations:\n",
    "                return \"Location\"\n",
    "            elif any(i in info['parameters'] for i in ['coordinates', 'locations']) and not(any(i in info['parameters'] for i in ['date', 'founded', 'founder', 'founders'])):\n",
    "                return 'W_Location'\n",
    "            \n",
    "            else:\n",
    "                return \"Other\"\n",
    "            #tieto clanky maju len kategorie\n",
    "        elif infobox == 'no infobox/redirect':\n",
    "            if list(filter(lambda x: regex.search('(compan[y|ies])(?i)', x), info['categories'])):\n",
    "                return 'Q_Company'\n",
    "            elif list(filter(lambda x: regex.search('(organisations*)(?i)', x), info['categories'])):\n",
    "                return 'Q_Organization'\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    def processArticle(title, text):\n",
    "        infobox = getInfobox(text)\n",
    "        \n",
    "        if infobox == \"redirect\":\n",
    "            info = regex.search(redirect_title, text).group(0)\n",
    "        \n",
    "        elif infobox == 'no infobox/redirect':\n",
    "            info = {'categories': list(getCategories(text))}\n",
    "        \n",
    "        else:\n",
    "            info = getArticleAtributes(infobox, text)\n",
    "\n",
    "        return (title, infobox, info, text, predictCategory(infobox, info, text))\n",
    "    return processArticle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs: https://docs.python.org/3.8/library/xml.sax.handler.html\n",
    "class ContentHandler(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        xml.sax.handler.ContentHandler.__init__(self)\n",
    "        self._buf = None\n",
    "        self._last_tag = None\n",
    "        self._parts = {}\n",
    "        self.output = []\n",
    "        self.article_process = ArticleHandler()\n",
    "\n",
    "    def characters(self, content):\n",
    "        if self._last_tag:\n",
    "            self._buf.append(content)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == 'page':\n",
    "            self._parts = {}\n",
    "        if name in ('title', 'text'):\n",
    "            self._last_tag = name\n",
    "            self._buf = []\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if name == self._last_tag:\n",
    "            self._parts[name] = ''.join(self._buf)\n",
    "        \n",
    "        #whole article\n",
    "        if name == 'page':\n",
    "            #function for process whole article in future\n",
    "            self.output.append(self.article_process(**self._parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parseWiki(limit = 2000, save = False, test_sample=False, data = '/home/xminarikd/.keras/datasets/enwiki-20201001-pages-articles9.xml-p2936261p4045402.bz2'):\n",
    "    \n",
    "    if test_sample:\n",
    "        data = os.getcwd().rsplit('/', 1)[0]\n",
    "        data = f'{data}/data/sample_wiki_articles2.xml.bz2'\n",
    "        print(data)\n",
    "    \n",
    "    handler = ContentHandler()\n",
    "\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setContentHandler(handler)\n",
    "\n",
    "    for i, line in enumerate(subprocess.Popen(['bzcat'], \n",
    "                             stdin = open(data), \n",
    "                             stdout = subprocess.PIPE).stdout):\n",
    "\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(f'Spracovanych {i + 1} riadkov.', end = '\\r')\n",
    "        try:\n",
    "            parser.feed(line)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        # get only some results\n",
    "        if len(handler.output) >= limit:\n",
    "            break\n",
    "        \n",
    "    if save:\n",
    "        output_dir = os.getcwd().rsplit('/', 1)[0]\n",
    "        partition_name = data.split('/')[-1].split('-')[-1].split('.')[0]\n",
    "        output_file = f'{output_dir}/output/{partition_name}.json'\n",
    "\n",
    "        with open(output_file, 'w+') as file:\n",
    "            for x in handler.output:\n",
    "                file.write(json.dumps({x[0]:x[4]}) + '\\n')\n",
    "\n",
    "    \n",
    "    return handler.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stiahnutie a parsovanie stránky wikipédie, ktorá obsahuje zoznam typov infoboxov. Tento zoznam obsahuje aj členeie týchto typov do rôznych kategórií. Vďaka tomuto je možné jednoducho získať všetky infoboxy, ktoré sú spojené napríklad s osobami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "infobox_list_url = 'https://en.wikipedia.org/wiki/Wikipedia:List_of_infoboxes'\n",
    "infobox_list_html = requests.get(infobox_list_url).text\n",
    "soup_dump = BeautifulSoup(infobox_list_html, 'html.parser')\n",
    "#sib = soup_dump.find_all(\"div\" ,{'id': 'toc'}).next_sibling\n",
    "\n",
    "template_list = dict();\n",
    "prev = None\n",
    "prev_tag = None\n",
    "prev_parent = None\n",
    "prev_parent_tag = 2\n",
    "\n",
    "for i, sibling in enumerate(soup_dump.find(id=\"toc\").next_siblings):\n",
    "    \n",
    "    if prev_parent == 'Other':\n",
    "        break\n",
    "    \n",
    "    if sibling.name == 'h2':\n",
    "        template_list[sibling.findChild().text] = {}\n",
    "        prev_parent = sibling.findChild().text\n",
    "        prev_tag = 2\n",
    "    \n",
    "    if sibling.name == 'h3':\n",
    "        if prev_tag < 3:\n",
    "            template_list[prev_parent][sibling.findChild().text] = list()\n",
    "            prev_tag = 3\n",
    "            prev = sibling.findChild().text\n",
    "            \n",
    "        if prev_tag == 3:\n",
    "            template_list[prev_parent][sibling.findChild().text] = list()\n",
    "            prev = sibling.findChild().text\n",
    "            \n",
    "    if sibling.name == 'ul':\n",
    "        a = sibling.find_all('a', title=re.compile('^Template:Infobox'))\n",
    "        b = map(lambda x: regex.findall('(?<=Template:Infobox )(.*)(?i)', x.text.lower()), a)\n",
    "        c = reduce(lambda x,y: x+y, b, list())\n",
    "        \n",
    "        if prev_tag >=3:\n",
    "            template_list[prev_parent][prev] = [y for x in [template_list[prev_parent][prev], list(c)] for y in x] \n",
    "        else:\n",
    "            template_list[prev_parent] = list(c)\n",
    "#template_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = list(reduce(lambda x,y: x+y, template_list[\"Person\"].values()))\n",
    "locations = list(reduce(lambda x,y: x+y, template_list[\"Place\"].values()))\n",
    "companies = template_list['Society and social science']['Business and economics']\n",
    "organizations = template_list['Society and social science']['Organization']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spustenie funkcie na spracovanie súborov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xminarikd/Documents/VINF/data/sample_wiki_articles2.xml.bz2\n",
      "David Stagg <--> Person\n",
      "Amaranthus mantegazzianus <--> redirect\n",
      "Amaranthus quitensis <--> redirect\n",
      "KTXT <--> None\n",
      "Maud Queen of Norway <--> redirect\n",
      "Milligram per litre <--> redirect\n",
      "Utica Psychiatric Center <--> Location\n",
      "Wikipedia:Articles for deletion/Studiomuscle <--> None\n",
      "Olean Wholesale Grocery <--> Q_Company\n",
      "Queen Tiye <--> redirect\n",
      "Queen Hatshepsut <--> redirect\n",
      "Clibanarii <--> None\n",
      "File:Hanns Martin Schleyer in captivity.jpg <--> None\n",
      "Political documentary <--> redirect\n",
      "Wikipedia:Articles for deletion/Slarp <--> None\n",
      "Final fantasy legends <--> redirect\n",
      "Queen Marie Amelie Therese <--> redirect\n",
      "Political documentaries <--> redirect\n",
      "E-767 <--> redirect\n",
      "Wikipedia:Articles for deletion/\"dirty thirty\" <--> None\n",
      "Prince Edward-Lennox <--> redirect\n",
      "Arthur Hill (actor) <--> Person\n",
      "Periodic paralysis <--> Other\n",
      "Greenstripe <--> redirect\n",
      "Amaranthus cruentus <--> None\n",
      "Careless weed <--> redirect\n",
      "Zamil idris <--> redirect\n",
      "Khada sag <--> redirect\n",
      "Million instructions per second <--> redirect\n",
      "Ashtadiggajas <--> None\n",
      "John C.Harsanyi <--> redirect\n",
      "Soci\\xc3\\xa9t\\xc3\\xa9 entomologique de France <--> None\n",
      "Sangorache <--> redirect\n",
      "Joseph's coat <--> redirect\n",
      "Recipients of the Distinguished Service Award of the Order of the Arrow <--> None\n",
      "Josephscoat <--> redirect\n",
      "Joseph's-coat <--> redirect\n",
      "URM Stores <--> Q_Company\n",
      "General purpose technology <--> None\n",
      "Rough skinned newt <--> redirect\n",
      "Queen Sophie Dorothea of Hanover <--> redirect\n",
      "Cefepime <--> None\n",
      "Larry Zerner <--> Person\n",
      "World of Illushions Starring Mickey Mouse and Donald Duck <--> redirect\n",
      "Category:Aberdeen, Hong Kong <--> None\n",
      "United Retail Merchants <--> redirect\n",
      "URM <--> None\n",
      "Plassenburg <--> None\n",
      "U.R.M. <--> redirect\n",
      "Turriaco <--> W_Location\n",
      "Piggly Wiggly Alabama Distributing Company <--> redirect\n",
      "Queen Eleanor of Aquitaine <--> redirect\n",
      "Crenshaw Company <--> Q_Company\n",
      "Osmia ribifloris <--> None\n",
      "San Pier d'Isonzo <--> W_Location\n",
      "Early life of Hugo Ch\\xc3\\xa1vez <--> Person\n"
     ]
    }
   ],
   "source": [
    "data = parseWiki(test_sample=True, save=True)\n",
    "\n",
    "for i, x in enumerate(data):\n",
    "    if i > 150:\n",
    "        break\n",
    "    if x[1] == 'redirect':\n",
    "        print(x[0], '<-->', x[1])\n",
    "    else:\n",
    "        print(x[0], '<-->', x[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and data searching area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <==> b'<mediawiki xmlns=\"http://www.mediawiki.org/xml/export-0.10/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd\" version=\"0.10\" xml:lang=\"en\">\\n'\n",
      "1 <==> b'  <siteinfo>\\n'\n",
      "2 <==> b'    <sitename>Wikipedia</sitename>\\n'\n",
      "3 <==> b'    <dbname>enwiki</dbname>\\n'\n",
      "4 <==> b'    <base>https://en.wikipedia.org/wiki/Main_Page</base>\\n'\n",
      "5 <==> b'    <generator>MediaWiki 1.36.0-wmf.10</generator>\\n'\n",
      "6 <==> b'    <case>first-letter</case>\\n'\n",
      "7 <==> b'    <namespaces>\\n'\n",
      "8 <==> b'      <namespace key=\"-2\" case=\"first-letter\">Media</namespace>\\n'\n",
      "9 <==> b'      <namespace key=\"-1\" case=\"first-letter\">Special</namespace>\\n'\n",
      "10 <==> b'      <namespace key=\"0\" case=\"first-letter\" />\\n'\n",
      "11 <==> b'      <namespace key=\"1\" case=\"first-letter\">Talk</namespace>\\n'\n",
      "12 <==> b'      <namespace key=\"2\" case=\"first-letter\">User</namespace>\\n'\n",
      "13 <==> b'      <namespace key=\"3\" case=\"first-letter\">User talk</namespace>\\n'\n",
      "14 <==> b'      <namespace key=\"4\" case=\"first-letter\">Wikipedia</namespace>\\n'\n",
      "15 <==> b'      <namespace key=\"5\" case=\"first-letter\">Wikipedia talk</namespace>\\n'\n",
      "16 <==> b'      <namespace key=\"6\" case=\"first-letter\">File</namespace>\\n'\n",
      "17 <==> b'      <namespace key=\"7\" case=\"first-letter\">File talk</namespace>\\n'\n",
      "18 <==> b'      <namespace key=\"8\" case=\"first-letter\">MediaWiki</namespace>\\n'\n",
      "19 <==> b'      <namespace key=\"9\" case=\"first-letter\">MediaWiki talk</namespace>\\n'\n",
      "20 <==> b'      <namespace key=\"10\" case=\"first-letter\">Template</namespace>\\n'\n",
      "21 <==> b'      <namespace key=\"11\" case=\"first-letter\">Template talk</namespace>\\n'\n",
      "22 <==> b'      <namespace key=\"12\" case=\"first-letter\">Help</namespace>\\n'\n",
      "23 <==> b'      <namespace key=\"13\" case=\"first-letter\">Help talk</namespace>\\n'\n",
      "24 <==> b'      <namespace key=\"14\" case=\"first-letter\">Category</namespace>\\n'\n",
      "25 <==> b'      <namespace key=\"15\" case=\"first-letter\">Category talk</namespace>\\n'\n",
      "26 <==> b'      <namespace key=\"100\" case=\"first-letter\">Portal</namespace>\\n'\n",
      "27 <==> b'      <namespace key=\"101\" case=\"first-letter\">Portal talk</namespace>\\n'\n",
      "28 <==> b'      <namespace key=\"108\" case=\"first-letter\">Book</namespace>\\n'\n",
      "29 <==> b'      <namespace key=\"109\" case=\"first-letter\">Book talk</namespace>\\n'\n",
      "30 <==> b'      <namespace key=\"118\" case=\"first-letter\">Draft</namespace>\\n'\n",
      "31 <==> b'      <namespace key=\"119\" case=\"first-letter\">Draft talk</namespace>\\n'\n",
      "32 <==> b'      <namespace key=\"446\" case=\"first-letter\">Education Program</namespace>\\n'\n",
      "33 <==> b'      <namespace key=\"447\" case=\"first-letter\">Education Program talk</namespace>\\n'\n",
      "34 <==> b'      <namespace key=\"710\" case=\"first-letter\">TimedText</namespace>\\n'\n",
      "35 <==> b'      <namespace key=\"711\" case=\"first-letter\">TimedText talk</namespace>\\n'\n",
      "36 <==> b'      <namespace key=\"828\" case=\"first-letter\">Module</namespace>\\n'\n",
      "37 <==> b'      <namespace key=\"829\" case=\"first-letter\">Module talk</namespace>\\n'\n",
      "38 <==> b'      <namespace key=\"2300\" case=\"first-letter\">Gadget</namespace>\\n'\n",
      "39 <==> b'      <namespace key=\"2301\" case=\"first-letter\">Gadget talk</namespace>\\n'\n",
      "40 <==> b'      <namespace key=\"2302\" case=\"case-sensitive\">Gadget definition</namespace>\\n'\n",
      "41 <==> b'      <namespace key=\"2303\" case=\"case-sensitive\">Gadget definition talk</namespace>\\n'\n",
      "42 <==> b'    </namespaces>\\n'\n",
      "43 <==> b'  </siteinfo>\\n'\n",
      "44 <==> b'  <page>\\n'\n",
      "45 <==> b'    <title>David Stagg</title>\\n'\n",
      "46 <==> b'    <ns>0</ns>\\n'\n",
      "47 <==> b'    <id>2936265</id>\\n'\n",
      "48 <==> b'    <revision>\\n'\n",
      "49 <==> b'      <id>976695836</id>\\n'\n",
      "50 <==> b'      <parentid>942490144</parentid>\\n'\n",
      "51 <==> b'      <timestamp>2020-09-04T12:52:41Z</timestamp>\\n'\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(subprocess.Popen(['bzcat'], \n",
    "                              stdin = open(test_data_path), \n",
    "                              stdout = subprocess.PIPE).stdout):\n",
    "    print(i,'<==>', line)\n",
    "    if i > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Stagg</td>\n",
       "      <td>{Infobox rugby league biography\\n'\\nb'|name   ...</td>\n",
       "      <td>{'type': 'rugby league biography\\n'', 'paramet...</td>\n",
       "      <td>{{short description|Australian rugby league fo...</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amaranthus mantegazzianus</td>\n",
       "      <td>redirect</td>\n",
       "      <td>Amaranthus caudatus</td>\n",
       "      <td>#REDIRECT [[Amaranthus caudatus]]\\n'\\nb'\\n'\\nb...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amaranthus quitensis</td>\n",
       "      <td>redirect</td>\n",
       "      <td>Amaranthus hybridus</td>\n",
       "      <td>#redirect [[Amaranthus hybridus]] {{R from tax...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KTXT</td>\n",
       "      <td>no infobox/redirect</td>\n",
       "      <td>{'categories': []}</td>\n",
       "      <td>\\'\\'\\'KTXT\\'\\'\\' may refer to:\\n'\\nb'\\n'\\nb'* ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maud Queen of Norway</td>\n",
       "      <td>redirect</td>\n",
       "      <td>Maud of Wales</td>\n",
       "      <td>#REDIRECT [[Maud of Wales]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Milligram per litre</td>\n",
       "      <td>redirect</td>\n",
       "      <td>Gram per litre</td>\n",
       "      <td>#REDIRECT [[Gram per litre]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Utica Psychiatric Center</td>\n",
       "      <td>{Infobox NRHP | name =Utica State Hospital, Ma...</td>\n",
       "      <td>{'type': 'nrhp', 'parameters': ['name', 'nrhp_...</td>\n",
       "      <td>{{Use mdy dates|date=December 2017}}\\n'\\nb'{{I...</td>\n",
       "      <td>Location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia:Articles for deletion/Studiomuscle</td>\n",
       "      <td>no infobox/redirect</td>\n",
       "      <td>{'categories': []}</td>\n",
       "      <td>&lt;div class=\"boilerplate metadata vfd\" style=\"b...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Olean Wholesale Grocery</td>\n",
       "      <td>no infobox/redirect</td>\n",
       "      <td>{'categories': ['Companies based in Cattaraugu...</td>\n",
       "      <td>{{Citation style|date=October 2019}}[[File:Ole...</td>\n",
       "      <td>Q_Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Queen Tiye</td>\n",
       "      <td>redirect</td>\n",
       "      <td>Tiye</td>\n",
       "      <td>#REDIRECT[[Tiye]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0  \\\n",
       "0                                   David Stagg   \n",
       "1                     Amaranthus mantegazzianus   \n",
       "2                          Amaranthus quitensis   \n",
       "3                                          KTXT   \n",
       "4                          Maud Queen of Norway   \n",
       "5                           Milligram per litre   \n",
       "6                      Utica Psychiatric Center   \n",
       "7  Wikipedia:Articles for deletion/Studiomuscle   \n",
       "8                       Olean Wholesale Grocery   \n",
       "9                                    Queen Tiye   \n",
       "\n",
       "                                                   1  \\\n",
       "0  {Infobox rugby league biography\\n'\\nb'|name   ...   \n",
       "1                                           redirect   \n",
       "2                                           redirect   \n",
       "3                                no infobox/redirect   \n",
       "4                                           redirect   \n",
       "5                                           redirect   \n",
       "6  {Infobox NRHP | name =Utica State Hospital, Ma...   \n",
       "7                                no infobox/redirect   \n",
       "8                                no infobox/redirect   \n",
       "9                                           redirect   \n",
       "\n",
       "                                                   2  \\\n",
       "0  {'type': 'rugby league biography\\n'', 'paramet...   \n",
       "1                                Amaranthus caudatus   \n",
       "2                                Amaranthus hybridus   \n",
       "3                                 {'categories': []}   \n",
       "4                                      Maud of Wales   \n",
       "5                                     Gram per litre   \n",
       "6  {'type': 'nrhp', 'parameters': ['name', 'nrhp_...   \n",
       "7                                 {'categories': []}   \n",
       "8  {'categories': ['Companies based in Cattaraugu...   \n",
       "9                                               Tiye   \n",
       "\n",
       "                                                   3          4  \n",
       "0  {{short description|Australian rugby league fo...     Person  \n",
       "1  #REDIRECT [[Amaranthus caudatus]]\\n'\\nb'\\n'\\nb...       None  \n",
       "2  #redirect [[Amaranthus hybridus]] {{R from tax...       None  \n",
       "3  \\'\\'\\'KTXT\\'\\'\\' may refer to:\\n'\\nb'\\n'\\nb'* ...       None  \n",
       "4                        #REDIRECT [[Maud of Wales]]       None  \n",
       "5                       #REDIRECT [[Gram per litre]]       None  \n",
       "6  {{Use mdy dates|date=December 2017}}\\n'\\nb'{{I...   Location  \n",
       "7  <div class=\"boilerplate metadata vfd\" style=\"b...       None  \n",
       "8  {{Citation style|date=October 2019}}[[File:Ole...  Q_Company  \n",
       "9                                  #REDIRECT[[Tiye]]       None  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rugby league biography', 'No infobox', 'NRHP', 'person',\n",
       "       'medical condition (new)', 'Italian comune', 'sports season',\n",
       "       'NFL player', 'school', 'character', 'officeholder', 'comic',\n",
       "       'UK place', 'song', 'military unit', 'medical person', 'bridge',\n",
       "       'Basketball club', 'civilian attack'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person                  284\n",
       "settlement              255\n",
       "album                   192\n",
       "airport                 153\n",
       "football biography      148\n",
       "                       ... \n",
       "Public transit            1\n",
       "Congressperson            1\n",
       "cattle breed              1\n",
       "Monstertruck              1\n",
       "laboratory equipment      1\n",
       "Name: 1, Length: 444, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redirect\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/xminarikd/.keras/datasets/enwiki-20201001-pages-articles9.xml-p2936261p4045402.bz2'\n",
    "sample_data_path = '/home/xminarikd/Documents/VINF/data/sample_wiki_articles2.xml.bz2'\n",
    "# Object for handling xml\n",
    "handler = ContentHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "for i, line in enumerate(subprocess.Popen(['bzcat'], \n",
    "                         stdin = open(data_path), \n",
    "                         stdout = subprocess.PIPE).stdout):\n",
    "    parser.feed(line)\n",
    "    \n",
    "    if len(handler.output) > 20000:\n",
    "        break\n",
    "\n",
    "print(handler.output[2][1])\n",
    "#print(regex.search(exp_inf_type, infobox).group().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Turriaco</td>\n",
       "      <td>{Infobox Italian comune\\n'\\nb'| name          ...</td>\n",
       "      <td>{'type': 'italian comune\\n'', 'parameters': ['...</td>\n",
       "      <td>{{Infobox Italian comune\\n'\\nb'| name         ...</td>\n",
       "      <td>W_Location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>San Pier d'Isonzo</td>\n",
       "      <td>{Infobox Italian comune\\n'\\nb'| name          ...</td>\n",
       "      <td>{'type': 'italian comune\\n'', 'parameters': ['...</td>\n",
       "      <td>{{Unreferenced|date=December 2009}}\\n'\\nb'{{In...</td>\n",
       "      <td>W_Location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "49           Turriaco  {Infobox Italian comune\\n'\\nb'| name          ...   \n",
       "54  San Pier d'Isonzo  {Infobox Italian comune\\n'\\nb'| name          ...   \n",
       "\n",
       "                                                    2  \\\n",
       "49  {'type': 'italian comune\\n'', 'parameters': ['...   \n",
       "54  {'type': 'italian comune\\n'', 'parameters': ['...   \n",
       "\n",
       "                                                    3           4  \n",
       "49  {{Infobox Italian comune\\n'\\nb'| name         ...  W_Location  \n",
       "54  {{Unreferenced|date=December 2009}}\\n'\\nb'{{In...  W_Location  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data)\n",
    "rr = df2.loc[df2[4] == 'W_Location']\n",
    "rr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speciesbox\n",
    "Citation\n",
    "Image\n",
    "div\n",
    "Licensing\n",
    "summary\n",
    "May refers to\n",
    "Use dmy dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': ['History of Atlanta',\n",
       "  'North Carolina in the American Civil War',\n",
       "  'Shipping companies of the United States',\n",
       "  'Companies based in Virginia']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data[52][2]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shipping companies of the United States', 'Companies based in Virginia']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp5 = ['History of Atlanta',\n",
    "  'North Carolina in the American Civil War',\n",
    "  'Shipping companies of the United States',\n",
    "  'Companies based in Virginia']\n",
    "list(filter(lambda x: regex.search('(compan[y|ies])(?i)', x), temp5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ano\n"
     ]
    }
   ],
   "source": [
    "temp2 = ['ano','nie jasd sad', 'asdasdasd asd']\n",
    "temp3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Organisations based in Manama']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: regex.search('(organisations*|associations*)(?i)', x),temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p2936261p4045402'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = '/home/xminarikd/.keras/datasets/enwiki-20201001-pages-articles9.xml-p2936261p4045402.bz2'\n",
    "tt.split('/')[-1].split('-')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xminarikd/Documents/VINF/data/sample_wiki_articles2.xml.bz2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "dirname = os.getcwd().rsplit('/', 1)[0]\n",
    "dirname = f'{dirname}/data/sample_wiki_articles2.xml.bz2'\n",
    "dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xminarikd/.keras/datasets/enwiki-20201001-pages-articles9.xml-p2936261p4045402.bz2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = '/home/xminarikd/.keras/datasets/enwiki-20201001-pages-articles9.xml-p2936261p4045402.bz2'\n",
    "tt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
